# 爬虫开发规范

## 1. 总体原则

### 1.1 防屏蔽措施
所有爬虫必须实现以下防屏蔽措施：

- **随机延迟**: 每次请求之间等待 3-6 秒随机时间
- **最大页数限制**: 每次爬取最多 5 页
- **重试机制**: 失败后最多重试 3 次，重试间隔 5-8 秒
- **HTTP状态码处理**:
  - 429 (请求过于频繁): 等待 10-15 秒后重试
  - 403 (访问被拒绝): 等待 30-40 秒后重试
- **完整请求头**: 包含 User-Agent, Accept, Accept-Language, Referer 等

### 1.2 超时设置
- 连接超时: 30秒
- 读取超时: 30秒
- 写入超时: 30秒

## 2. 数据获取策略

### 2.1 列表页
列表页只获取基本信息：
- 小说ID (novelId)
- 小说标题
- 作者
- 封面URL (coverUrl)

### 2.2 详情页
详情页获取完整信息：
- 更新时间
- 简介
- 标签
- 字数
- 状态

### 2.3 增量爬取
根据上一次爬取时间判断是否继续爬取：

```java
if (sinceTime != null && fullNovel.getLatestUpdateTime() != null) {
    if (!fullNovel.getLatestUpdateTime().isAfter(sinceTime)) {
        log.info("小说 {} 更新时间 {} 早于或等于增量时间 {}，停止继续爬取", 
            fullNovel.getTitle(), fullNovel.getLatestUpdateTime(), sinceTime);
        shouldStop.set(true);
        break;
    }
}
```

当检测到小说更新时间早于或等于增量时间时，立即停止爬取，避免重复处理。

## 3. 爬取流程

```
1. 获取列表页总页数
2. 遍历每一页:
   a. 解析列表页，获取小说基本信息
   b. 对每本小说:
      - 随机延迟
      - 获取详情页，获取更新时间和简介
      - 检查更新时间是否早于增量时间
        - 是: 停止爬取
        - 否: 添加到结果列表
   c. 页面之间随机延迟
3. 返回结果
```

## 4. 代码模板

### 4.1 常量定义
```java
private static final int MIN_DELAY_MS = 3000;
private static final int MAX_DELAY_MS = 6000;
private static final int MAX_PAGES = 5;
private static final int MAX_RETRIES = 3;
```

### 4.2 随机延迟
```java
private void randomDelay() {
    try {
        int delay = MIN_DELAY_MS + random.nextInt(MAX_DELAY_MS - MIN_DELAY_MS);
        log.debug("等待 {} 毫秒", delay);
        Thread.sleep(delay);
    } catch (InterruptedException e) {
        Thread.currentThread().interrupt();
    }
}
```

### 4.3 重试机制
```java
private Response executeWithRetry(Request request) throws Exception {
    Exception lastException = null;
    
    for (int i = 0; i < MAX_RETRIES; i++) {
        try {
            Response response = httpClient.newCall(request).execute();
            
            if (response.code() == 429) {
                log.warn("请求过于频繁，等待后重试...");
                response.close();
                Thread.sleep(10000 + random.nextInt(5000));
                continue;
            }
            
            if (response.code() == 403) {
                log.warn("访问被拒绝，可能被屏蔽，等待后重试...");
                response.close();
                Thread.sleep(30000 + random.nextInt(10000));
                continue;
            }
            
            return response;
        } catch (Exception e) {
            lastException = e;
            log.warn("请求失败，第 {} 次重试: {}", i + 1, e.getMessage());
            if (i < MAX_RETRIES - 1) {
                Thread.sleep(5000 + random.nextInt(3000));
            }
        }
    }
    
    throw lastException != null ? lastException : new Exception("请求失败");
}
```

## 5. 各平台特殊说明

### 5.1 SF轻小说
- 列表页URL: `https://book.sfacg.com/List/default.aspx?ud=7&PageIndex={page}`
- 详情页URL: `https://book.sfacg.com/Novel/{novelId}/`
- 目录页URL: `https://book.sfacg.com/Novel/{novelId}/MainIndex/`
- 更新时间格式: `yyyy/M/d H:mm:ss`
- 列表页选择器: `.Comic_Pic_List`
- 详情页选择器: `.text-row .text`, `.introduce`

### 5.2 刺猬猫
- 列表页URL: `https://www.ciweimao.com/get-search-book-list/0-0-uptime-3-0-0/全部//{page}`
- 详情页URL: `https://www.ciweimao.com/book/{novelId}`
- 更新时间格式: `yyyy-MM-dd HH:mm:ss` 或相对时间（X分钟前、X小时前等）
- 列表页选择器: `.rank-book-list li[data-book-id]`
- 详情页选择器: `meta[property=og:novel:*]`, `.update-time`

### 5.3 次元姬
- 列表页URL: `https://www.ciyuanji.com/l_c_0_0_0_0_3_{page}_10.html`
- 详情页URL: `https://www.ciyuanji.com/b_d_{novelId}.html`
- 章节页URL: `https://www.ciyuanji.com/chapter/{novelId}_{chapterId}.html`
- 更新时间格式: `yyyy-MM-dd HH:mm:ss`
- 列表页选择器: `.card_item__BZXh0`, `.BookCard_title__nQGag`
- 详情页选择器: `.book_detail_time__E3K_Y`, `.book_detail_tag__dIVn_`, `.book_detail_article__tNriO`

## 6. 测试要求

每个爬虫必须包含以下测试用例：
1. 测试爬取列表
2. 测试爬取详情
3. 测试爬取章节
4. 测试解析更新时间
5. 测试增量爬取逻辑
